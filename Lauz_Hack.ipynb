{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[615. 536. 236.  49.   8.   0.]\n",
      " [608. 561. 209.  60.   6.   0.]\n",
      " [620. 537. 236.  45.   5.   1.]\n",
      " ...\n",
      " [595. 574. 229.  42.   3.   1.]\n",
      " [596. 573. 235.  32.   7.   1.]\n",
      " [578. 519. 197.  40.   7.   0.]] [[3.78418963]\n",
      " [3.76120012]\n",
      " [3.73766962]\n",
      " ...\n",
      " [1.09861229]\n",
      " [0.69314718]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# input from txt\n",
    "file=open(\"data.txt\",\"r\")\n",
    "x_train=np.empty(1)\n",
    "y_train=np.empty(1)\n",
    "\n",
    "for i in file.readlines():\n",
    "    if \" \" in i:\n",
    "        valori = i.split()\n",
    "        valori = list(map(lambda x: int(x),valori))\n",
    "        y_train=np.append(y_train, valori[0])\n",
    "        x_train=np.append(x_train, valori[1:])\n",
    "x_train = x_train[1:]\n",
    "y_train = y_train[1:]\n",
    "x_train = x_train.reshape(-1,6)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_train = np.log(y_train)\n",
    "\n",
    "print(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: an input of tensor([0., 1., 2., 3., 4., 5.]) gives a prediction:\n",
      " tensor([0., 0., 0., 0., 0., 0.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "        # define the parameters of the model (weights and biases)\n",
    "        self.w = torch.tensor([0.], requires_grad=True)\n",
    "        self.b = torch.tensor([0.], requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # implement forward computation - compute predictions based on the inputs\n",
    "        return self.w * x + self.b\n",
    "    \n",
    "    def parameters(self):\n",
    "        # this function should return a list of parameters of the model\n",
    "        return [self.w, self.b]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # convenience function\n",
    "        return self.forward(x)\n",
    "    \n",
    "\n",
    "def lossfunc(pred, y):\n",
    "    # implement the MSE loss function\n",
    "    return (1+abs(pred - y)).mean()\n",
    "\n",
    "model = MyLinearRegression()\n",
    "numpy_inputs = np.asarray([0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=np.float32)\n",
    "torch_inputs = torch.from_numpy(numpy_inputs)\n",
    "torch_outputs = model(torch_inputs)\n",
    "print(\"Testing model: an input of %s gives a prediction:\\n %s\" % (torch_inputs, torch_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, model, lossfunc, optimizer, num_epoch):\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        # create torch variables corresponding to features and labels\n",
    "        inputs = torch.from_numpy(features)\n",
    "        targets = torch.from_numpy(labels)\n",
    "\n",
    "        # Step 2 - compute model predictions and loss\n",
    "        outputs = model(inputs)\n",
    "        loss = lossfunc(outputs, targets)\n",
    "        \n",
    "        # Step 3 - do a backward pass and a gradient update step\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Loss: 4.4386\n",
      "Epoch [51/10000], Loss: 4.4372\n",
      "Epoch [101/10000], Loss: 4.4355\n",
      "Epoch [151/10000], Loss: 4.4412\n",
      "Epoch [201/10000], Loss: 4.4394\n",
      "Epoch [251/10000], Loss: 4.4428\n",
      "Epoch [301/10000], Loss: 4.4431\n",
      "Epoch [351/10000], Loss: 4.4526\n",
      "Epoch [401/10000], Loss: 4.4578\n",
      "Epoch [451/10000], Loss: 4.4590\n",
      "Epoch [501/10000], Loss: 4.4626\n",
      "Epoch [551/10000], Loss: 4.4666\n",
      "Epoch [601/10000], Loss: 4.4657\n",
      "Epoch [651/10000], Loss: 4.4723\n",
      "Epoch [701/10000], Loss: 4.4839\n",
      "Epoch [751/10000], Loss: 4.4831\n",
      "Epoch [801/10000], Loss: 4.4855\n",
      "Epoch [851/10000], Loss: 4.4884\n",
      "Epoch [901/10000], Loss: 4.4897\n",
      "Epoch [951/10000], Loss: 4.4879\n",
      "Epoch [1001/10000], Loss: 4.4919\n",
      "Epoch [1051/10000], Loss: 4.5000\n",
      "Epoch [1101/10000], Loss: 4.5061\n",
      "Epoch [1151/10000], Loss: 4.5072\n",
      "Epoch [1201/10000], Loss: 4.5166\n",
      "Epoch [1251/10000], Loss: 4.5334\n",
      "Epoch [1301/10000], Loss: 4.5454\n",
      "Epoch [1351/10000], Loss: 4.5679\n",
      "Epoch [1401/10000], Loss: 4.5755\n",
      "Epoch [1451/10000], Loss: 4.5828\n",
      "Epoch [1501/10000], Loss: 4.5895\n",
      "Epoch [1551/10000], Loss: 4.6057\n",
      "Epoch [1601/10000], Loss: 4.6285\n",
      "Epoch [1651/10000], Loss: 4.6324\n",
      "Epoch [1701/10000], Loss: 4.6603\n",
      "Epoch [1751/10000], Loss: 4.6879\n",
      "Epoch [1801/10000], Loss: 4.7032\n",
      "Epoch [1851/10000], Loss: 4.7088\n",
      "Epoch [1901/10000], Loss: 4.7115\n",
      "Epoch [1951/10000], Loss: 4.7140\n",
      "Epoch [2001/10000], Loss: 4.7228\n",
      "Epoch [2051/10000], Loss: 4.7279\n",
      "Epoch [2101/10000], Loss: 4.7407\n",
      "Epoch [2151/10000], Loss: 4.7532\n",
      "Epoch [2201/10000], Loss: 4.7553\n",
      "Epoch [2251/10000], Loss: 4.7793\n",
      "Epoch [2301/10000], Loss: 4.8042\n",
      "Epoch [2351/10000], Loss: 4.8096\n",
      "Epoch [2401/10000], Loss: 4.8316\n",
      "Epoch [2451/10000], Loss: 4.8625\n",
      "Epoch [2501/10000], Loss: 4.8875\n",
      "Epoch [2551/10000], Loss: 4.9003\n",
      "Epoch [2601/10000], Loss: 4.9101\n",
      "Epoch [2651/10000], Loss: 4.9188\n",
      "Epoch [2701/10000], Loss: 4.9393\n",
      "Epoch [2751/10000], Loss: 4.9700\n",
      "Epoch [2801/10000], Loss: 4.9767\n",
      "Epoch [2851/10000], Loss: 4.9880\n",
      "Epoch [2901/10000], Loss: 4.9911\n",
      "Epoch [2951/10000], Loss: 4.9985\n",
      "Epoch [3001/10000], Loss: 5.0112\n",
      "Epoch [3051/10000], Loss: 5.0260\n",
      "Epoch [3101/10000], Loss: 5.0490\n",
      "Epoch [3151/10000], Loss: 5.0702\n",
      "Epoch [3201/10000], Loss: 5.0901\n",
      "Epoch [3251/10000], Loss: 5.0910\n",
      "Epoch [3301/10000], Loss: 5.1038\n",
      "Epoch [3351/10000], Loss: 5.1240\n",
      "Epoch [3401/10000], Loss: 5.1340\n",
      "Epoch [3451/10000], Loss: 5.1557\n",
      "Epoch [3501/10000], Loss: 5.1816\n",
      "Epoch [3551/10000], Loss: 5.1901\n",
      "Epoch [3601/10000], Loss: 5.2078\n",
      "Epoch [3651/10000], Loss: 5.2304\n",
      "Epoch [3701/10000], Loss: 5.2391\n",
      "Epoch [3751/10000], Loss: 5.2509\n",
      "Epoch [3801/10000], Loss: 5.2829\n",
      "Epoch [3851/10000], Loss: 5.3162\n",
      "Epoch [3901/10000], Loss: 5.3570\n",
      "Epoch [3951/10000], Loss: 5.3842\n",
      "Epoch [4001/10000], Loss: 5.4121\n",
      "Epoch [4051/10000], Loss: 5.4359\n",
      "Epoch [4101/10000], Loss: 5.4517\n",
      "Epoch [4151/10000], Loss: 5.4831\n",
      "Epoch [4201/10000], Loss: 5.5297\n",
      "Epoch [4251/10000], Loss: 5.5499\n",
      "Epoch [4301/10000], Loss: 5.5633\n",
      "Epoch [4351/10000], Loss: 5.5912\n",
      "Epoch [4401/10000], Loss: 5.6361\n",
      "Epoch [4451/10000], Loss: 5.6760\n",
      "Epoch [4501/10000], Loss: 5.7194\n",
      "Epoch [4551/10000], Loss: 5.7607\n",
      "Epoch [4601/10000], Loss: 5.7869\n",
      "Epoch [4651/10000], Loss: 5.8265\n",
      "Epoch [4701/10000], Loss: 5.8826\n",
      "Epoch [4751/10000], Loss: 5.8971\n",
      "Epoch [4801/10000], Loss: 5.9386\n",
      "Epoch [4851/10000], Loss: 5.9860\n",
      "Epoch [4901/10000], Loss: 6.0302\n",
      "Epoch [4951/10000], Loss: 6.0487\n",
      "Epoch [5001/10000], Loss: 6.0813\n",
      "Epoch [5051/10000], Loss: 6.1203\n",
      "Epoch [5101/10000], Loss: 6.1787\n",
      "Epoch [5151/10000], Loss: 6.2093\n",
      "Epoch [5201/10000], Loss: 6.2286\n",
      "Epoch [5251/10000], Loss: 6.2620\n",
      "Epoch [5301/10000], Loss: 6.2983\n",
      "Epoch [5351/10000], Loss: 6.3288\n",
      "Epoch [5401/10000], Loss: 6.3836\n",
      "Epoch [5451/10000], Loss: 6.4164\n",
      "Epoch [5501/10000], Loss: 6.4952\n",
      "Epoch [5551/10000], Loss: 6.5528\n",
      "Epoch [5601/10000], Loss: 6.5788\n",
      "Epoch [5651/10000], Loss: 6.6209\n",
      "Epoch [5701/10000], Loss: 6.6459\n",
      "Epoch [5751/10000], Loss: 6.6947\n",
      "Epoch [5801/10000], Loss: 6.7472\n",
      "Epoch [5851/10000], Loss: 6.8125\n",
      "Epoch [5901/10000], Loss: 6.8675\n",
      "Epoch [5951/10000], Loss: 6.9169\n",
      "Epoch [6001/10000], Loss: 6.9584\n",
      "Epoch [6051/10000], Loss: 7.0177\n",
      "Epoch [6101/10000], Loss: 7.0790\n",
      "Epoch [6151/10000], Loss: 7.1524\n",
      "Epoch [6201/10000], Loss: 7.2077\n",
      "Epoch [6251/10000], Loss: 7.2501\n",
      "Epoch [6301/10000], Loss: 7.2993\n",
      "Epoch [6351/10000], Loss: 7.3790\n",
      "Epoch [6401/10000], Loss: 7.4589\n",
      "Epoch [6451/10000], Loss: 7.5097\n",
      "Epoch [6501/10000], Loss: 7.5815\n",
      "Epoch [6551/10000], Loss: 7.6254\n",
      "Epoch [6601/10000], Loss: 7.7132\n",
      "Epoch [6651/10000], Loss: 7.7795\n",
      "Epoch [6701/10000], Loss: 7.8089\n",
      "Epoch [6751/10000], Loss: 7.8745\n",
      "Epoch [6801/10000], Loss: 7.9411\n",
      "Epoch [6851/10000], Loss: 7.9850\n",
      "Epoch [6901/10000], Loss: 8.0347\n",
      "Epoch [6951/10000], Loss: 8.0631\n",
      "Epoch [7001/10000], Loss: 8.1355\n",
      "Epoch [7051/10000], Loss: 8.2169\n",
      "Epoch [7101/10000], Loss: 8.2783\n",
      "Epoch [7151/10000], Loss: 8.3550\n",
      "Epoch [7201/10000], Loss: 8.3953\n",
      "Epoch [7251/10000], Loss: 8.4803\n",
      "Epoch [7301/10000], Loss: 8.5713\n",
      "Epoch [7351/10000], Loss: 8.6749\n",
      "Epoch [7401/10000], Loss: 8.7349\n",
      "Epoch [7451/10000], Loss: 8.8013\n",
      "Epoch [7501/10000], Loss: 8.8770\n",
      "Epoch [7551/10000], Loss: 8.9488\n",
      "Epoch [7601/10000], Loss: 9.0591\n",
      "Epoch [7651/10000], Loss: 9.1481\n",
      "Epoch [7701/10000], Loss: 9.2025\n",
      "Epoch [7751/10000], Loss: 9.2483\n",
      "Epoch [7801/10000], Loss: 9.2817\n",
      "Epoch [7851/10000], Loss: 9.3290\n",
      "Epoch [7901/10000], Loss: 9.4323\n",
      "Epoch [7951/10000], Loss: 9.4918\n",
      "Epoch [8001/10000], Loss: 9.5311\n",
      "Epoch [8051/10000], Loss: 9.5929\n",
      "Epoch [8101/10000], Loss: 9.6525\n",
      "Epoch [8151/10000], Loss: 9.6741\n",
      "Epoch [8201/10000], Loss: 9.7348\n",
      "Epoch [8251/10000], Loss: 9.8051\n",
      "Epoch [8301/10000], Loss: 9.8480\n",
      "Epoch [8351/10000], Loss: 9.9117\n",
      "Epoch [8401/10000], Loss: 9.9815\n",
      "Epoch [8451/10000], Loss: 10.0584\n",
      "Epoch [8501/10000], Loss: 10.1437\n",
      "Epoch [8551/10000], Loss: 10.2393\n",
      "Epoch [8601/10000], Loss: 10.3162\n",
      "Epoch [8651/10000], Loss: 10.4164\n",
      "Epoch [8701/10000], Loss: 10.5512\n",
      "Epoch [8751/10000], Loss: 10.6749\n",
      "Epoch [8801/10000], Loss: 10.7863\n",
      "Epoch [8851/10000], Loss: 10.8324\n",
      "Epoch [8901/10000], Loss: 10.8974\n",
      "Epoch [8951/10000], Loss: 10.9762\n",
      "Epoch [9001/10000], Loss: 11.0478\n",
      "Epoch [9051/10000], Loss: 11.1338\n",
      "Epoch [9101/10000], Loss: 11.2016\n",
      "Epoch [9151/10000], Loss: 11.2836\n",
      "Epoch [9201/10000], Loss: 11.3799\n",
      "Epoch [9251/10000], Loss: 11.4488\n",
      "Epoch [9301/10000], Loss: 11.5299\n",
      "Epoch [9351/10000], Loss: 11.6177\n",
      "Epoch [9401/10000], Loss: 11.7169\n",
      "Epoch [9451/10000], Loss: 11.8134\n",
      "Epoch [9501/10000], Loss: 11.9355\n",
      "Epoch [9551/10000], Loss: 12.0504\n",
      "Epoch [9601/10000], Loss: 12.1724\n",
      "Epoch [9651/10000], Loss: 12.3046\n",
      "Epoch [9701/10000], Loss: 12.4112\n",
      "Epoch [9751/10000], Loss: 12.5214\n",
      "Epoch [9801/10000], Loss: 12.6490\n",
      "Epoch [9851/10000], Loss: 12.7653\n",
      "Epoch [9901/10000], Loss: 12.8654\n",
      "Epoch [9951/10000], Loss: 12.9747\n"
     ]
    }
   ],
   "source": [
    "# training and visualizing predictions made by linear regression model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "train(features=x_train,\n",
    "      labels=y_train,\n",
    "      model=model,\n",
    "      lossfunc=lossfunc, \n",
    "      optimizer=optimizer,\n",
    "      num_epoch=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (using nn package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c70c3945e278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m       \u001b[0mlossfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlossfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m       num_epoch=1000)\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-ad36bbc9fae8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(features, labels, model, lossfunc, optimizer, num_epoch)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Step 2 - compute model predictions and loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-c70c3945e278>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# implement forward computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# training and visualizing predictions made by linear regression model (nn package)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "class NNLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNLinearRegression, self).__init__()\n",
    "        # define the parameters of the model (linear nn layer)\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # implement forward computation\n",
    "        return self.linear(x)\n",
    "    \n",
    "# training and visualizing predictions made by linear regression model (nn package)\n",
    "# use loss function from nn package\n",
    "lossfunc = nn.MSELoss()\n",
    "\n",
    "model = NNLinearRegression()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "train(features=x_train,\n",
    "      labels=y_train,\n",
    "      model=model,\n",
    "      lossfunc=lossfunc,\n",
    "      optimizer=optimizer,\n",
    "      num_epoch=1000)\n",
    "visualize(x_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-579d8e61e6ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m       \u001b[0mlossfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlossfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m       num_epoch=300)\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-ad36bbc9fae8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(features, labels, model, lossfunc, optimizer, num_epoch)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Step 2 - compute model predictions and loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-579d8e61e6ab>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # define parameters / layers of a multi-layered perceptron with one hidden layer\n",
    "        self.fc1 = nn.Linear(1, hidden_size)\n",
    "        self.activation_fn = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc2(self.activation_fn(self.fc1(x)))\n",
    "        return out\n",
    "    \n",
    "# possibly change learning rate, hidden size, and optimizer type for multi-layered perceptron\n",
    "hidden_size = 3\n",
    "learning_rate = 1.5e-1\n",
    "\n",
    "model = MLP(hidden_size=hidden_size)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(features=x_train,\n",
    "      labels=y_train,\n",
    "      model=model,\n",
    "      lossfunc=lossfunc,\n",
    "      optimizer=optimizer,\n",
    "      num_epoch=300)\n",
    "visualize(x_train, y_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
